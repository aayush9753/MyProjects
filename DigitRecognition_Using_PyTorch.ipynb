{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DigitRecognition_Using_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsPW5ksWfJtrRyK1kyUPwe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayush9753/MyProjects/blob/main/DigitRecognition_Using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4erbgMBYHjzO"
      },
      "source": [
        "Mounting the drive to get the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VhNpZWcWGVo",
        "outputId": "864c8009-a153-4168-c591-3bf7d3bbbdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fF_htJKHo7X"
      },
      "source": [
        "#Imprting the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnOYG2O4V3-8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler, Adam, SGD\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIzKfvsdHwou"
      },
      "source": [
        "# Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACwRmQtuXx0g"
      },
      "source": [
        "train=pd.read_csv('/content/drive/My Drive/Data/Digit_Recognition/train.csv')\n",
        "test=pd.read_csv('/content/drive/My Drive/Data/Digit_Recognition/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NZU4alXYZ-U",
        "outputId": "0047c5d9-c85f-4293-e4ae-92d55a8b255e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yh2ElkdH2JR"
      },
      "source": [
        "# Preprocessing the Raw Data\n",
        "As the Data is having 785 columns which have m 28*28*1 images and their labels.\n",
        "We are converting the data in aproper format to feed them in the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNEJ71QMYdjJ"
      },
      "source": [
        "#Getting the label column\n",
        "train_labels = np.array(train['label'])\n",
        "# m = No of Exaples\n",
        "m_train = train.shape[0] #m in training data\n",
        "m_test = test.shape[0]  #m in testing data\n",
        "#reshaping the long 1D vector of shape 1*784 into a 3D vector of shape 1*28*28 \n",
        "train_data = np.array(train.loc[:,'pixel0':]).reshape(m_train,1,28,28)\n",
        "test_data = np.array(test.loc[:,'pixel0':]).reshape(m_test,1,28,28)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOKxiPMSI20_"
      },
      "source": [
        "#Visualising the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qul1mT_kbDL_",
        "outputId": "6a3bfe9f-ca35-459b-a883-698f3882ef63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "k = 0\n",
        "while k<2:\n",
        "    i = random.randint(0,42000)\n",
        "    plt.imshow(train_data[i,0,:,:])\n",
        "    plt.show()\n",
        "    print(f\"The label for the above image is {train_labels[i]}\")\n",
        "    k+=1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOEElEQVR4nO3dbYxc5XnG8evyuzAx2JhaDji8k8ihrdNscXkpoUVJCR8CfCgNVamrIpa00CYtrYKoWmirSlbahEYCpVmCi0kIUVQgOI2j4KxQUZrW9Rq5fsEQu9QIXGMDRjEg4jfufthDtIGdZ9czZ+aMff9/0mpmzj0z52bE5TPnPHPO44gQgGPflKYbANAbhB1IgrADSRB2IAnCDiQxrZcrm+GZMUuze7lKIJWf6A0diP0er9ZR2G1fLumLkqZK+kpELC89f5Zma6kv62SVAArWxnDLWttf421PlXS3pI9LWizpWtuL230/AN3VyT77+ZK2R8SzEXFA0jckXVlPWwDq1knYT5H0/JjHL1TLfobtQdsjtkcOan8HqwPQia4fjY+IoYgYiIiB6ZrZ7dUBaKGTsO+UtGjM41OrZQD6UCdhXyfpHNtn2J4h6ZOSVtXTFoC6tT30FhGHbN8s6XsaHXpbERFbausMQK06GmePiNWSVtfUC4Au4ueyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNHRLK7oD9NOf1/L2tY/XVh87a0f/XaxPnjC/7XV02Tcv29+sX7nXdcU6wvuWV+sx/79R9zTsayjsNveIek1SYclHYqIgTqaAlC/OrbsvxYRL9fwPgC6iH12IIlOwx6SHrO93vbgeE+wPWh7xPbIQbEPBTSl06/xF0fETts/J2mN7acj4omxT4iIIUlDkjTH86LD9QFoU0db9ojYWd3ukfSIpPPraApA/doOu+3Ztt/z9n1JH5O0ua7GANTLEe19s7Z9pka35tLo7sDXI+LvSq+Z43mx1Je1tb5j2pSpxfKeTy0t1pfdtLpl7Y9OfLatlo4G//Tj04r173yi9Ujw4e3/W3c7fWFtDGtf7PV4tbb32SPiWUm/2HZXAHqKoTcgCcIOJEHYgSQIO5AEYQeS4BTXHph26inF+ra/L5/qufWSu+ps55jxqROeKz9hVetSaVhOOjaH5tiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLP3wO7LW1/qWZK2XnJ3jzqp36YDB9t+7c/PmF5jJ+9WGod/69Hydu67V324WD+87eg7dZgtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7D7xyYftj0Z1af+Bwsf71vRcU68MPluf9WPToi0fc09t+918fL9Z/8/hX2n7vifzhieXz1f/xr369WD/7ujq76Q227EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsx7g/WP7Hxfr8L/9Hsf5e/bBYL4/iS3Fh64l+z5yxZ4JXl6ey7qbPDnyvWP/W3PcX64dffbXOdmox4Zbd9grbe2xvHrNsnu01trdVt3O72yaATk3ma/x9ki5/x7JbJQ1HxDmShqvHAPrYhGGPiCck7X3H4islrazur5R0Vc19AahZu/vsCyJiV3X/RUkLWj3R9qCkQUmapePaXB2ATnV8ND4iQlIU6kMRMRARA9M1s9PVAWhTu2HfbXuhJFW3Ex1WBdCwdsO+StKy6v4ySY/W0w6Abplwn932g5IulTTf9guSbpe0XNI3bV8v6TlJ13SzSbRv6ideLj/hy529/5TzPlCsv/Dnrc/l//CMzsbRf3TwJ8X6d18/r+33/srTFxbrp725ve33bsqEYY+Ia1uULqu5FwBdxM9lgSQIO5AEYQeSIOxAEoQdSIJTXHvgtH9x+Qm/0b11P3jePxfr1z/2Ox29//KzHyjWf3nmBP/tHbjub28p1k+6t3z6bskibS7W32r7nZvDlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQeOW7ejWP/3/eV/cy+a2f6o7unTypcCG/7gw22/96jujaNvOlCe6vrkteXLNR+NY+HdxJYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0HDr/0UrH+1zdcX6z/5VD5nPRfnXXoiHs6Gtz8TKsLG4+avfnpHnVybGDLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7eB6YNry/WbxwpX9v9qYvvq7Gb/vHBebuK9efnzi3WD79aPt89mwm37LZX2N5je/OYZXfY3ml7Q/V3RXfbBNCpyXyNv0/S5eMsvzMillR/q+ttC0DdJgx7RDwhaW8PegHQRZ0coLvZ9sbqa37LnSfbg7ZHbI8c1P4OVgegE+2G/UuSzpK0RNIuSZ9v9cSIGIqIgYgYmK6Zba4OQKfaCntE7I6IwxHxlqR7JJ1fb1sA6tZW2G0vHPPwammC+W0BNM4RUX6C/aCkSyXNl7Rb0u3V4yWSQtIOSTdGRHlQVNIcz4ulvqyjhjOa8gsfKNZfWtp6vHntHXfX3U7fOPs7Nxbr5w6u61En/WNtDGtf7B33Yv4T/qgmIsa7gsC9HXcFoKf4uSyQBGEHkiDsQBKEHUiCsANJcIrrUeCtjeVLJk9dckGPOukv8xb+uOkWjips2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZjwJTzz6jWL/vb1peKEjSrHqbwVGLLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4ex+YOmdOsf7sdQuL9XOn5xxL37flpGJ9fo/6OFqwZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn74Eps2cX628+1HrKZUnasviuOts5aly9/Ypi/azbnyzWy5OR5zPhlt32ItuP237K9hbbn66Wz7O9xva26rb8fyyARk3ma/whSbdExGJJvyLpJtuLJd0qaTgizpE0XD0G0KcmDHtE7IqIJ6v7r0naKukUSVdKWlk9baWkq7rVJIDOHdE+u+3TJX1I0lpJCyJiV1V6UdKCFq8ZlDQoSbN0XLt9AujQpI/G2z5e0kOSPhMR+8bWIiLU4nhIRAxFxEBEDEzXzI6aBdC+SYXd9nSNBv2BiHi4Wrzb9sKqvlDSnu60CKAOE36Nt21J90raGhFfGFNaJWmZpOXV7aNd6fAYMOXEE4r17y9+pEed9JdvvXFisX7gz04u1mP/i3W2c8ybzD77RZKuk7TJ9oZq2W0aDfk3bV8v6TlJ13SnRQB1mDDsEfEDSW5RvqzedgB0Cz+XBZIg7EAShB1IgrADSRB2IAlOce2BVy59X9MtNOaCDb/Vsvbmv5XH0d+77od1t5MaW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9h44eHyrkwb73/Cb5asL/cmKG4r1RZ/7r5a1OLStrZ7QHrbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+w9MH/oP4v193/k94v1Zz6you11r9tfnrj4t799U7F+7tfeKNZPneCcc6ZN7h9s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCUeUR0JtL5J0v6QFGh02HYqIL9q+Q9INkl6qnnpbRKwuvdccz4ulZuJXoFvWxrD2xd5xL6AwmR/VHJJ0S0Q8afs9ktbbXlPV7oyIf6irUQDdM5n52XdJ2lXdf832VkmndLsxAPU6on1226dL+pCktdWim21vtL3C9twWrxm0PWJ75KD2d9QsgPZNOuy2j5f0kKTPRMQ+SV+SdJakJRrd8n9+vNdFxFBEDETEwHSVr2cGoHsmFXbb0zUa9Aci4mFJiojdEXE4It6SdI+k87vXJoBOTRh225Z0r6StEfGFMcsXjnna1ZI2198egLpM5mj8RZKuk7TJ9oZq2W2SrrW9RKPDcTsk3diVDgHUYjJH438gabxxu+KYOoD+wi/ogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSUx4KelaV2a/JOm5MYvmS3q5Zw0cmX7trV/7kuitXXX2dlpEnDxeoadhf9fK7ZGIGGisgYJ+7a1f+5LorV296o2v8UAShB1IoumwDzW8/pJ+7a1f+5LorV096a3RfXYAvdP0lh1AjxB2IIlGwm77ctvP2N5u+9YmemjF9g7bm2xvsD3ScC8rbO+xvXnMsnm219jeVt2OO8deQ73dYXtn9dltsH1FQ70tsv247adsb7H96Wp5o59doa+efG4932e3PVXSjyR9VNILktZJujYinuppIy3Y3iFpICIa/wGG7UskvS7p/og4r1r2OUl7I2J59Q/l3Ij4bJ/0doek15uexruarWjh2GnGJV0l6ffU4GdX6Osa9eBza2LLfr6k7RHxbEQckPQNSVc20Effi4gnJO19x+IrJa2s7q/U6P8sPdeit74QEbsi4snq/muS3p5mvNHPrtBXTzQR9lMkPT/m8Qvqr/neQ9JjttfbHmy6mXEsiIhd1f0XJS1osplxTDiNdy+9Y5rxvvns2pn+vFMcoHu3iyPilyR9XNJN1dfVvhSj+2D9NHY6qWm8e2WcacZ/qsnPrt3pzzvVRNh3Slo05vGp1bK+EBE7q9s9kh5R/01FvfvtGXSr2z0N9/NT/TSN93jTjKsPPrsmpz9vIuzrJJ1j+wzbMyR9UtKqBvp4F9uzqwMnsj1b0sfUf1NRr5K0rLq/TNKjDfbyM/plGu9W04yr4c+u8enPI6Lnf5Ku0OgR+f+R9BdN9NCirzMl/Xf1t6Xp3iQ9qNGvdQc1emzjekknSRqWtE3S9yXN66Pevippk6SNGg3WwoZ6u1ijX9E3StpQ/V3R9GdX6Ksnnxs/lwWS4AAdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTx/0nBHo/p8HIjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The label for the above image is 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The label for the above image is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZiIO2PqJJTU"
      },
      "source": [
        "### Splitting the data into Training, Validation and Testing Set\n",
        "We are using 90% data for training, 5% for Validation and 5% for Testing purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWIIRtfobPqI"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.1, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zv7zZoILk_i"
      },
      "source": [
        "###Transformer\n",
        " Making a Transformer to convert our data into the PyTorch Tensors and Normalize the data.\n",
        " We are converting the data with Mean = 0.5 and STD = 0.5 across the channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSzI8eqDAln"
      },
      "source": [
        "# transformations to be applied on images\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjvJ5ngUMT1V"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT_Z2ms1bUqo"
      },
      "source": [
        "class DigitDataset(Dataset):\n",
        "\n",
        "    def __init__(self,images,labels,transfrom = transform):\n",
        "        # Initialize data, download, etc.\n",
        "        self.x_data = torch.from_numpy(images/255.) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(labels) # size [n_samples, 1]\n",
        "        self.n_samples = images.shape[0]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwdkS_8-Ayaa"
      },
      "source": [
        "train_dataset = DigitDataset(X_train,y_train)\n",
        "val_dataset = DigitDataset(X_val,y_val)\n",
        "test_dataset = DigitDataset(X_test,y_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Du2z9XiMZBk"
      },
      "source": [
        "### Creating Dataloaders\n",
        "We will use Batch-Size = 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE-5mOuQA0SZ"
      },
      "source": [
        "batch_size=64\n",
        "# defining trainloader, valloader and testloader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnAs8nZmMkq5"
      },
      "source": [
        "##### Visualising the Data-loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDh9jNhlCE_f",
        "outputId": "77fb8d50-ea93-4c44-bf36-b72708c6bcec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# shape of training data\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc7e-GevDdOI",
        "outputId": "db2a4c79-16b4-4364-c2a2-bcd1564237e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# visualizing the training images\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa3cf089d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nndMZO4gDmb3",
        "outputId": "bcdfde28-9b0e-470c-ba52-5dec9a8601e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# shape of validation data\n",
        "dataiter = iter(val_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw0QVHNID6sN",
        "outputId": "5a3d82bb-e913-4627-f462-f69fe02f49c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Checking the device type\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXVa7rpkMwIt"
      },
      "source": [
        "#Model Building\n",
        "Our Model is taking 1*28*28 Images as input and having the output with dimension = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuBYDbvEFKTb"
      },
      "source": [
        "# defining the model architecture\n",
        "class Net(nn.Module):   \n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      self.cnn_layers = nn.Sequential(\n",
        "          # Defining a 2D convolution layer\n",
        "          nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(4),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          # Defining another 2D convolution layer\n",
        "          nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(4),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      )\n",
        "\n",
        "      self.linear_layers = nn.Sequential(\n",
        "          nn.Linear(4 * 7 * 7, 10)\n",
        "      )\n",
        "\n",
        "  # Defining the forward pass    \n",
        "  def forward(self, x):\n",
        "      x = self.cnn_layers(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.linear_layers(x)\n",
        "      return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyJwfYHYNOVC"
      },
      "source": [
        "Defining the Optimizer, Criterion (loss function) and Learning Rate Scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI2nuKEDD3ZC",
        "outputId": "c65673ea-78af-42ba-9cd3-da1f32f7e725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "# defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=196, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6PJIV8cNo4j"
      },
      "source": [
        "## Training of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0EidxFwYVFj"
      },
      "source": [
        "dataset_sizes = {}\n",
        "dataset_sizes['train'] = len(train_dataset)\n",
        "dataset_sizes['val'] = len(val_dataset)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSF1rrsBRY1l"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
        "    since = time.time() #Return the time in seconds since the epoch as a floating point number\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = train_loader\n",
        "    dataloaders['val'] = val_loader\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohYWnHvxGSVj",
        "outputId": "e82a08d0-a20e-4612-c59f-ec3ba1b24d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=50)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.0592 Acc: 0.9807\n",
            "val Loss: 0.0921 Acc: 0.9671\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.0410 Acc: 0.9872\n",
            "val Loss: 0.0708 Acc: 0.9786\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.0382 Acc: 0.9879\n",
            "val Loss: 0.0698 Acc: 0.9781\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.0364 Acc: 0.9885\n",
            "val Loss: 0.0696 Acc: 0.9776\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0361 Acc: 0.9886\n",
            "val Loss: 0.0723 Acc: 0.9762\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0346 Acc: 0.9894\n",
            "val Loss: 0.0699 Acc: 0.9795\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0349 Acc: 0.9894\n",
            "val Loss: 0.0701 Acc: 0.9771\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0344 Acc: 0.9891\n",
            "val Loss: 0.0689 Acc: 0.9771\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0315 Acc: 0.9905\n",
            "val Loss: 0.0683 Acc: 0.9790\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0313 Acc: 0.9906\n",
            "val Loss: 0.0683 Acc: 0.9795\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0312 Acc: 0.9910\n",
            "val Loss: 0.0685 Acc: 0.9800\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0313 Acc: 0.9907\n",
            "val Loss: 0.0685 Acc: 0.9790\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0308 Acc: 0.9909\n",
            "val Loss: 0.0687 Acc: 0.9790\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0305 Acc: 0.9908\n",
            "val Loss: 0.0690 Acc: 0.9795\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0309 Acc: 0.9907\n",
            "val Loss: 0.0688 Acc: 0.9795\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0305 Acc: 0.9908\n",
            "val Loss: 0.0689 Acc: 0.9795\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0302 Acc: 0.9911\n",
            "val Loss: 0.0688 Acc: 0.9800\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9909\n",
            "val Loss: 0.0689 Acc: 0.9795\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0305 Acc: 0.9909\n",
            "val Loss: 0.0690 Acc: 0.9795\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0305 Acc: 0.9909\n",
            "val Loss: 0.0685 Acc: 0.9795\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9907\n",
            "val Loss: 0.0689 Acc: 0.9800\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0302 Acc: 0.9911\n",
            "val Loss: 0.0687 Acc: 0.9800\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9909\n",
            "val Loss: 0.0687 Acc: 0.9795\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0302 Acc: 0.9909\n",
            "val Loss: 0.0688 Acc: 0.9800\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9910\n",
            "val Loss: 0.0690 Acc: 0.9800\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9909\n",
            "val Loss: 0.0692 Acc: 0.9795\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0301 Acc: 0.9914\n",
            "val Loss: 0.0687 Acc: 0.9795\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0305 Acc: 0.9908\n",
            "val Loss: 0.0686 Acc: 0.9800\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9909\n",
            "val Loss: 0.0691 Acc: 0.9800\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9911\n",
            "val Loss: 0.0686 Acc: 0.9795\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9909\n",
            "val Loss: 0.0689 Acc: 0.9795\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9908\n",
            "val Loss: 0.0685 Acc: 0.9795\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0302 Acc: 0.9911\n",
            "val Loss: 0.0689 Acc: 0.9805\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0301 Acc: 0.9913\n",
            "val Loss: 0.0687 Acc: 0.9800\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9910\n",
            "val Loss: 0.0691 Acc: 0.9805\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0301 Acc: 0.9913\n",
            "val Loss: 0.0692 Acc: 0.9800\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9908\n",
            "val Loss: 0.0687 Acc: 0.9790\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9909\n",
            "val Loss: 0.0690 Acc: 0.9800\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0300 Acc: 0.9911\n",
            "val Loss: 0.0688 Acc: 0.9790\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9909\n",
            "val Loss: 0.0686 Acc: 0.9800\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9908\n",
            "val Loss: 0.0685 Acc: 0.9795\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9909\n",
            "val Loss: 0.0686 Acc: 0.9805\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9910\n",
            "val Loss: 0.0686 Acc: 0.9795\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9908\n",
            "val Loss: 0.0687 Acc: 0.9800\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0300 Acc: 0.9911\n",
            "val Loss: 0.0688 Acc: 0.9800\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9910\n",
            "val Loss: 0.0686 Acc: 0.9800\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9911\n",
            "val Loss: 0.0688 Acc: 0.9800\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0304 Acc: 0.9908\n",
            "val Loss: 0.0691 Acc: 0.9805\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0307 Acc: 0.9908\n",
            "val Loss: 0.0690 Acc: 0.9800\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0306 Acc: 0.9909\n",
            "val Loss: 0.0687 Acc: 0.9795\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.980476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bQhpk2OQTmU"
      },
      "source": [
        "### Testing our model on test-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugph61YsSxCL",
        "outputId": "5f8ffbaa-3922-4245-ea0b-ee231c20db77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# getting predictions on test set and measuring the performance\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in test_loader:\n",
        "  for i in range(len(labels)):\n",
        "    images = images.cuda()\n",
        "    images = images.type(torch.cuda.FloatTensor)\n",
        "    labels = labels.cuda()\n",
        "    img = images[i].view(1, 1, 28, 28)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    \n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.cpu()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 2100\n",
            "\n",
            "Model Accuracy = 0.9795238095238096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrWCsO0yQc7_"
      },
      "source": [
        "### Predicting for unlabelled Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0VbgSK1WhHh"
      },
      "source": [
        "test = test_data/255 #Normalizing the data\n",
        "test = torch.from_numpy(test)  # Converting into Tensors\n",
        "test = test.type(torch.cuda.FloatTensor) "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YllsGqYWiDj"
      },
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(test.cuda())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1AM1hAtQ45v"
      },
      "source": [
        "Outputs are the output of the final linear Layer having shape = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv2Bf1mrXJBV"
      },
      "source": [
        "ps = torch.exp(outputs)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51sUjSUORdau"
      },
      "source": [
        "#max_value is the value of highest no. in each 10-dim vector \n",
        "#index is the index of that max value \n",
        "max_value, index = torch.max(ps,axis=1) "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhObNkLlZFmQ"
      },
      "source": [
        "index = index.cpu()\n",
        "#Converting Prediction to numpy for Submission\n",
        "prediction = index.numpy()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLDxAo2LauqN",
        "outputId": "af6a6b29-d694-41da-eb8d-8fe4c1659fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tbN93j2a1JL"
      },
      "source": [
        "k = np.arange(1,28001)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDnSA9vjR-gO"
      },
      "source": [
        "Saving the Prediction in the acceptable format "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX4Krl3NZGSg"
      },
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"ImageId\":k ,\n",
        "        \"Label\": prediction\n",
        "\n",
        "    })\n",
        "\n",
        "submission.to_csv('Digit_Recognition_submission.csv', index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il-8tTvPaiWs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}